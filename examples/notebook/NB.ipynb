{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 16, 6, 5, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = randn(N, D_in)\n",
    "np.random.seed(2)\n",
    "y = randn(N, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 5), (5,), (5, 2), (2,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "w1 = randn(D_in, H) \n",
    "np.random.seed(23)\n",
    "b1 = randn(H)\n",
    "np.random.seed(4)\n",
    "w2 = randn(H, D_out)\n",
    "np.random.seed(24)\n",
    "b2 = randn(D_out)\n",
    "w1.shape, b1.shape, w2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bias = False\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(6, 5, bias=use_bias)\n",
    "        self.l2 = nn.Linear(5, 2, bias=use_bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.l1(x))\n",
    "        x= self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAD(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(DAD, self).__init__()\n",
    "        self.out_activations = []\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, *inputs, **kwargs):\n",
    "        childrens = dict(self.model.named_children())\n",
    "        for k, ch in childrens.items():\n",
    "            ch.register_forward_hook(self.hook_wrapper('forward', k))\n",
    "        return self.model(*inputs, **kwargs)\n",
    "    \n",
    "    def hook_wrapper(self, hook_type, layer):\n",
    "        def hook_save(a, in_grad, out_grad):\n",
    "            if hook_type.lower() == 'forward':\n",
    "                self.out_activations.append(out_grad)\n",
    "        return hook_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DAD(Net())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n, m), w in zip(net.named_parameters(), [w1, w2]):\n",
    "    if 'bias' in n:\n",
    "        m.data = torch.FloatTensor(w)\n",
    "    elif 'weight' in n:\n",
    "        m.data = torch.FloatTensor(w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "o = net(torch.FloatTensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.square(o-torch.Tensor(y)).sum()\n",
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 4.8668e+00, -7.3101e-01,  3.3871e+00, -2.9787e+00,  6.3070e-01],\n",
       "         [ 2.8090e+00, -3.3843e-01,  3.8158e+00, -9.8379e-01, -8.6114e-01],\n",
       "         [-6.5381e-01,  9.8198e-01,  2.7928e+00,  2.1106e+00,  1.9173e+00],\n",
       "         [-5.7622e-01, -1.5003e+00, -1.8400e+00, -1.0349e+00, -2.6426e+00],\n",
       "         [ 2.3340e+00,  1.2404e+00,  1.3691e+00, -3.2487e+00,  1.2505e+00],\n",
       "         [ 9.5366e-01, -2.8573e-01, -1.1422e-01, -8.4773e-01,  1.9675e+00],\n",
       "         [-3.7027e+00,  3.8523e-02, -8.0047e-02,  6.2751e+00, -1.3253e-01],\n",
       "         [-3.4696e+00,  1.1946e+00, -1.5707e-01, -7.9400e-01, -5.7030e-01],\n",
       "         [ 1.3477e+00,  4.7508e-01, -1.2094e+00, -8.6205e-02,  1.3253e+00],\n",
       "         [-3.0312e+00,  5.8591e-01, -8.0356e-01,  2.0979e+00, -1.6977e+00],\n",
       "         [-2.8721e+00,  3.3434e-02,  7.9310e-01,  2.1075e+00, -5.1581e-01],\n",
       "         [ 1.2508e+00,  3.0449e+00,  1.1739e+00,  2.3414e-01,  2.2010e+00],\n",
       "         [ 1.5272e-01,  1.9597e+00,  2.2800e+00, -2.4939e+00,  1.9022e+00],\n",
       "         [ 1.0870e-03,  1.6754e-01, -1.2990e-01, -1.3114e+00, -5.0263e-01],\n",
       "         [ 9.0704e-02, -4.2728e-02, -1.2300e+00, -1.9910e+00, -9.4415e-01],\n",
       "         [ 2.2736e+00,  4.8826e-01,  1.2722e+00, -3.4700e+00, -1.9101e-01]],\n",
       "        grad_fn=<MmBackward>),\n",
       " tensor([[-4.8740e-01, -1.5157e+00],\n",
       "         [-8.4862e-01, -9.5418e-01],\n",
       "         [-1.3816e+00, -1.2694e+00],\n",
       "         [-3.6667e-01,  1.7399e-01],\n",
       "         [-8.1948e-01, -1.1230e+00],\n",
       "         [-4.8534e-01, -9.0304e-01],\n",
       "         [-1.1931e+00, -3.2574e-01],\n",
       "         [-1.0330e+00, -4.0345e-01],\n",
       "         [-7.1169e-01, -1.4748e-01],\n",
       "         [-1.2878e+00,  3.3988e-01],\n",
       "         [-1.2396e+00, -5.9844e-01],\n",
       "         [-1.2854e+00, -8.4167e-01],\n",
       "         [-9.7887e-01, -1.4980e+00],\n",
       "         [-7.1801e-01, -4.1106e-01],\n",
       "         [-5.3712e-01,  3.6621e-04],\n",
       "         [-7.6225e-01, -8.4170e-01]], grad_fn=<MmBackward>)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.out_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h: (16, 5)\n",
      "grad_y_pred: (16, 2)\n",
      "grad_w2:  (5, 2)\n",
      "grad_h:  (16, 5)\n",
      "grad_w1: (6, 5)\n"
     ]
    }
   ],
   "source": [
    "for t in range(10):\n",
    "    h = 1/(1+np.exp(-x.dot(w1)))\n",
    "    print('h:', h.shape)\n",
    "    y_pred = h.dot(w2)\n",
    "    loss1 = np.square(y_pred-y).sum()\n",
    "#     print(t, loss)\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    print('grad_y_pred:', grad_y_pred.shape)\n",
    "    \n",
    "    grad_w2 = h.T.dot(grad_y_pred)\n",
    "    print('grad_w2: ', grad_w2.shape)\n",
    "    \n",
    "    \n",
    "    grad_h = grad_y_pred.dot(w2.T)\n",
    "    print('grad_h: ', grad_h.shape)\n",
    "    grad_w1 = x.T.dot(grad_h * h * (1-h))\n",
    "    print('grad_w1:', grad_w1.shape)\n",
    "    \n",
    "    w1 -= 1e-4 * grad_w1\n",
    "    w2 -= 1e-4 * grad_w2\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(tensor([[-0.1413, -2.9189],\n",
       "          [ 2.5752, -5.1889],\n",
       "          [ 0.8237, -0.8552],\n",
       "          [-1.7391,  2.8386],\n",
       "          [ 0.4770, -0.4280],\n",
       "          [-2.0736, -6.3905],\n",
       "          [-2.4692,  1.5844],\n",
       "          [-3.1440,  0.3854],\n",
       "          [-1.3851, -2.6450],\n",
       "          [-1.0799,  0.6617],\n",
       "          [-0.7229, -0.8840],\n",
       "          [-3.0839,  0.2942],\n",
       "          [-1.2801, -2.5237],\n",
       "          [-0.1607,  1.5531],\n",
       "          [ 1.7682,  0.3077],\n",
       "          [-0.9864, -6.1461]]),),\n",
       " (tensor([[-1.1251e-02, -4.1559e-01,  1.4767e-01, -7.6393e-02,  7.4549e-01],\n",
       "          [-1.3361e-01, -1.5004e+00,  1.5012e-01, -9.4552e-01,  1.4183e+00],\n",
       "          [-8.7819e-02, -2.8038e-01,  5.4787e-02, -1.0068e-01,  1.4001e-01],\n",
       "          [ 3.1013e-01,  5.5268e-01, -4.4444e-01,  5.4632e-01, -2.3732e-01],\n",
       "          [-1.5456e-02, -1.3437e-01,  7.7126e-02, -2.0308e-02,  1.1226e-01],\n",
       "          [-6.7072e-01, -5.8676e-01,  2.7300e+00, -5.2336e-01,  7.1121e-01],\n",
       "          [ 1.5831e-02,  8.8895e-01, -3.6771e-01,  4.7716e-03, -6.5634e-01],\n",
       "          [ 9.5444e-04,  6.0509e-01,  1.7426e-01,  4.8471e-01, -3.4437e-01],\n",
       "          [-2.3081e-01, -1.1065e-01,  8.4144e-01, -1.7256e-01,  4.2448e-01],\n",
       "          [ 1.2254e-02,  3.5236e-01, -1.2711e-01,  1.0650e-01, -1.4620e-01],\n",
       "          [-2.4561e-02,  2.5442e-02,  3.6400e-01, -6.1153e-03,  1.7985e-01],\n",
       "          [-1.8056e-03,  1.4175e-01,  1.4796e-01,  5.3447e-01, -1.2277e-01],\n",
       "          [-3.3380e-01, -5.2801e-02,  3.8041e-01, -4.8383e-02,  2.7747e-01],\n",
       "          [ 1.9438e-01,  3.0841e-01, -5.9391e-01,  1.7303e-01, -4.2946e-01],\n",
       "          [ 6.1633e-02, -3.8527e-01, -2.1399e-01, -1.0117e-01,  4.8398e-02],\n",
       "          [-2.6747e-01, -7.7885e-01,  1.7296e+00, -8.9208e-02,  1.6583e+00]]),)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads = []\n",
    "for op in net.out_activations[::-1]:\n",
    "    grads.append(torch.autograd.grad(loss, op, retain_graph=True))\n",
    "    print('------------')\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1413, -2.9189],\n",
       "        [ 2.5752, -5.1889],\n",
       "        [ 0.8237, -0.8552],\n",
       "        [-1.7391,  2.8386],\n",
       "        [ 0.4770, -0.4280],\n",
       "        [-2.0736, -6.3905],\n",
       "        [-2.4692,  1.5844],\n",
       "        [-3.1440,  0.3854],\n",
       "        [-1.3851, -2.6450],\n",
       "        [-1.0799,  0.6617],\n",
       "        [-0.7229, -0.8840],\n",
       "        [-3.0839,  0.2942],\n",
       "        [-1.2801, -2.5237],\n",
       "        [-0.1607,  1.5531],\n",
       "        [ 1.7682,  0.3077],\n",
       "        [-0.9864, -6.1461]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1251e-02, -4.1559e-01,  1.4767e-01, -7.6393e-02,  7.4549e-01],\n",
       "        [-1.3361e-01, -1.5004e+00,  1.5012e-01, -9.4552e-01,  1.4183e+00],\n",
       "        [-8.7819e-02, -2.8038e-01,  5.4787e-02, -1.0068e-01,  1.4001e-01],\n",
       "        [ 3.1013e-01,  5.5268e-01, -4.4444e-01,  5.4632e-01, -2.3732e-01],\n",
       "        [-1.5456e-02, -1.3437e-01,  7.7126e-02, -2.0308e-02,  1.1226e-01],\n",
       "        [-6.7072e-01, -5.8676e-01,  2.7300e+00, -5.2336e-01,  7.1121e-01],\n",
       "        [ 1.5831e-02,  8.8895e-01, -3.6771e-01,  4.7716e-03, -6.5634e-01],\n",
       "        [ 9.5444e-04,  6.0509e-01,  1.7426e-01,  4.8471e-01, -3.4437e-01],\n",
       "        [-2.3081e-01, -1.1065e-01,  8.4144e-01, -1.7256e-01,  4.2448e-01],\n",
       "        [ 1.2254e-02,  3.5236e-01, -1.2711e-01,  1.0650e-01, -1.4620e-01],\n",
       "        [-2.4561e-02,  2.5442e-02,  3.6400e-01, -6.1153e-03,  1.7985e-01],\n",
       "        [-1.8056e-03,  1.4175e-01,  1.4796e-01,  5.3447e-01, -1.2277e-01],\n",
       "        [-3.3380e-01, -5.2801e-02,  3.8041e-01, -4.8383e-02,  2.7747e-01],\n",
       "        [ 1.9438e-01,  3.0841e-01, -5.9391e-01,  1.7303e-01, -4.2946e-01],\n",
       "        [ 6.1633e-02, -3.8527e-01, -2.1399e-01, -1.0117e-01,  4.8398e-02],\n",
       "        [-2.6747e-01, -7.7885e-01,  1.7296e+00, -8.9208e-02,  1.6583e+00]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14128343, -2.91890857],\n",
       "       [ 2.57515734, -5.18890603],\n",
       "       [ 0.82365203, -0.85523361],\n",
       "       [-1.73909922,  2.8385638 ],\n",
       "       [ 0.47695332, -0.42796761],\n",
       "       [-2.07359372, -6.39049049],\n",
       "       [-2.46923772,  1.58436757],\n",
       "       [-3.14404445,  0.38541964],\n",
       "       [-1.38512863, -2.64496736],\n",
       "       [-1.07988552,  0.66171606],\n",
       "       [-0.72291186, -0.88400441],\n",
       "       [-3.08388612,  0.29422503],\n",
       "       [-1.28009607, -2.52365231],\n",
       "       [-0.16070638,  1.55309877],\n",
       "       [ 1.76819895,  0.30772287],\n",
       "       [-0.9863842 , -6.1461239 ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
