{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 16, 6, 5, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = randn(N, D_in)\n",
    "np.random.seed(2)\n",
    "y = randn(N, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 5), (5,), (5, 2), (2,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "w1 = randn(D_in, H) \n",
    "np.random.seed(23)\n",
    "b1 = randn(H)\n",
    "np.random.seed(4)\n",
    "w2 = randn(H, D_out)\n",
    "np.random.seed(24)\n",
    "b2 = randn(D_out)\n",
    "w1.shape, b1.shape, w2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bias = False\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(6, 5, bias=use_bias)\n",
    "        self.l2 = nn.Linear(5, 2, bias=use_bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.l1(x))\n",
    "        x= self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAD(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(DAD, self).__init__()\n",
    "        self.in_activations = []\n",
    "        self.out_activations = []\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, *inputs, **kwargs):\n",
    "        childrens = dict(self.model.named_children())\n",
    "        for k, ch in childrens.items():\n",
    "            ch.register_forward_hook(self.hook_wrapper('forward', k))\n",
    "        return self.model(*inputs, **kwargs)\n",
    "    \n",
    "    def hook_wrapper(self, hook_type, layer):\n",
    "        def fw_hook(a, in_act, out_act):\n",
    "            print(f'----IN----------------------')\n",
    "            print(in_act)\n",
    "            print(f'{out_act.shape}----OUT----------------------')\n",
    "            print(out_act)\n",
    "            self.out_activations.append(out_act)\n",
    "            \n",
    "        return fw_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2008,  0.2095,  0.0986,  0.0346,  0.1878,  0.3414],\n",
       "         [-0.2846,  0.3429,  0.1499, -0.3898,  0.0625, -0.2702],\n",
       "         [-0.3645, -0.0525,  0.3633,  0.2582,  0.2732, -0.3415],\n",
       "         [-0.1669, -0.3569,  0.3770, -0.0248, -0.0676, -0.1150],\n",
       "         [ 0.0028,  0.0976,  0.1065,  0.3120, -0.0106,  0.0151]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1608, -0.4034,  0.0235,  0.2031, -0.1082],\n",
       "         [-0.1566, -0.2567,  0.1993,  0.0855, -0.3974]], requires_grad=True)]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (n, m), w in zip(net.named_parameters(), [w1, w2]):\n",
    "#     if 'bias' in n:\n",
    "#         m.data = torch.FloatTensor(w)\n",
    "#     elif 'weight' in n:\n",
    "#         m.data = torch.FloatTensor(w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.7320, -0.7529, -0.7772, -0.6544,  0.0859, -0.8904],\n",
       "         [ 0.4953, -0.4150, -0.5639, -0.4966,  0.0444, -0.4534],\n",
       "         [-0.9351,  0.5704,  0.3056,  0.7422, -0.3246,  0.8923],\n",
       "         [-0.7102,  0.4459, -0.1479,  0.6183, -0.4304,  0.7054],\n",
       "         [ 0.8702, -0.5116,  0.1916, -0.5230,  0.5253, -0.9120]]),\n",
       " tensor([[ 7.7468,  7.6690,  6.5837,  4.5025,  7.6624],\n",
       "         [-4.8424, -4.6252, -4.7298, -2.6999, -2.7696]])]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.grad for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "o = net(torch.FloatTensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.square(o-torch.Tensor(y)).sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-3.0949e-01,  6.7701e-01, -2.7613e-01,  6.1981e-01, -1.1317e-01],\n",
       "         [-5.4146e-01,  9.5455e-01, -4.4751e-02,  7.4017e-01,  1.1374e-01],\n",
       "         [-5.1835e-02, -6.1387e-01, -4.1699e-01, -7.7695e-02,  1.9880e-01],\n",
       "         [-3.8336e-01,  8.9481e-01, -1.8748e-01,  2.8392e-01, -3.6653e-01],\n",
       "         [-4.2680e-01, -3.5746e-01, -1.2701e-01,  6.0326e-01, -2.2469e-01],\n",
       "         [ 5.0284e-02, -4.0308e-01, -5.9826e-01, -9.1199e-02, -5.0808e-01],\n",
       "         [-1.6316e-01, -1.7522e-01, -4.6604e-02, -3.2974e-01,  2.5828e-01],\n",
       "         [-6.3542e-02, -8.3247e-01, -5.3156e-01, -1.4438e-01,  3.1628e-01],\n",
       "         [-2.6280e-01, -5.6114e-01,  1.3881e-01,  1.3879e-01,  4.9511e-03],\n",
       "         [-4.7197e-01,  2.0723e-04,  1.0304e-01,  1.7678e-01,  1.8024e-01],\n",
       "         [ 3.0157e-03, -2.6942e-01, -4.8579e-01, -2.8131e-01,  3.6532e-01],\n",
       "         [-4.4944e-01, -1.5067e+00,  5.8814e-01,  3.4188e-01,  9.8081e-01],\n",
       "         [-4.4859e-02, -1.1928e+00, -5.0857e-01,  9.1092e-02,  3.5961e-01],\n",
       "         [-2.8286e-01, -7.6473e-02, -1.8386e-01,  2.3137e-01,  2.9425e-02],\n",
       "         [-4.2063e-01,  1.6570e-01, -1.1753e-01,  3.9498e-01, -3.4966e-01],\n",
       "         [-4.4154e-01,  9.1011e-02, -1.0178e-01,  6.1511e-01, -1.2379e-02]],\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.5958,  0.4039],\n",
       "         [-0.5824,  0.4285],\n",
       "         [-0.6038,  0.2855],\n",
       "         [-0.5400,  0.3794],\n",
       "         [-0.6274,  0.3526],\n",
       "         [-0.5890,  0.2843],\n",
       "         [-0.5383,  0.2678],\n",
       "         [-0.6122,  0.2813],\n",
       "         [-0.5885,  0.2806],\n",
       "         [-0.5640,  0.3288],\n",
       "         [-0.5754,  0.2868],\n",
       "         [-0.6384,  0.2656],\n",
       "         [-0.6517,  0.2868],\n",
       "         [-0.5899,  0.3334],\n",
       "         [-0.5790,  0.3560],\n",
       "         [-0.6109,  0.3772]], grad_fn=<AddmmBackward>)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.out_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h: (16, 5)\n",
      "grad_y_pred: (16, 2)\n",
      "grad_w2:  (5, 2)\n",
      "grad_h:  (16, 5)\n",
      "grad_w1: (6, 5)\n"
     ]
    }
   ],
   "source": [
    "for t in range(10):\n",
    "    h = 1/(1+np.exp(-x.dot(w1)))\n",
    "    print('h:', h.shape)\n",
    "    y_pred = h.dot(w2)\n",
    "    loss1 = np.square(y_pred-y).sum()\n",
    "#     print(t, loss)\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    print('grad_y_pred:', grad_y_pred.shape)\n",
    "    \n",
    "    grad_w2 = h.T.dot(grad_y_pred)\n",
    "    print('grad_w2: ', grad_w2.shape)\n",
    "    \n",
    "    \n",
    "    grad_h = grad_y_pred.dot(w2.T)\n",
    "    print('grad_h: ', grad_h.shape)\n",
    "    grad_w1 = x.T.dot(grad_h * h * (1-h))\n",
    "    print('grad_w1:', grad_w1.shape)\n",
    "    \n",
    "    w1 -= 1e-4 * grad_w1\n",
    "    w2 -= 1e-4 * grad_w2\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "grad() missing 2 required positional arguments: 'outputs' and 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-f0f09f12e93c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: grad() missing 2 required positional arguments: 'outputs' and 'inputs'"
     ]
    }
   ],
   "source": [
    "torch.autograd.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.3580,  0.9204],\n",
       "         [ 3.1076, -2.4235],\n",
       "         [ 2.3793,  2.2546],\n",
       "         [-2.0858,  3.2493],\n",
       "         [ 0.8612,  2.5231],\n",
       "         [-2.2808, -4.0159],\n",
       "         [-1.1597,  2.7714],\n",
       "         [-2.3025,  1.7549],\n",
       "         [-1.1387, -1.7888],\n",
       "         [ 0.3678,  0.6395],\n",
       "         [ 0.6054,  0.8864],\n",
       "         [-1.7900,  2.5088],\n",
       "         [-0.6257,  1.0459],\n",
       "         [ 0.0955,  3.0421],\n",
       "         [ 1.6844,  1.0190],\n",
       "         [-0.6838, -3.7083]]),\n",
       " tensor([[-0.0482,  0.0227, -0.0753,  0.1077,  0.0257],\n",
       "         [ 0.0352,  0.0271,  0.2937, -0.4783, -0.1163],\n",
       "         [-0.2594,  0.1949, -0.0482, -0.0638, -0.0102],\n",
       "         [-0.1343,  0.0424, -0.3032,  0.4970,  0.1059],\n",
       "         [-0.2043,  0.1506, -0.1320,  0.1136,  0.0287],\n",
       "         [ 0.3788, -0.2783,  0.1579, -0.0986, -0.0241],\n",
       "         [-0.1442,  0.0722, -0.2346,  0.3555,  0.0781],\n",
       "         [-0.0251, -0.0227, -0.2005,  0.3996,  0.0835],\n",
       "         [ 0.1711, -0.1247,  0.0713, -0.0305, -0.0087],\n",
       "         [-0.0573,  0.0464, -0.0272,  0.0151,  0.0040],\n",
       "         [-0.0880,  0.0675, -0.0318,  0.0105,  0.0033],\n",
       "         [-0.0950,  0.0187, -0.2239,  0.3993,  0.0703],\n",
       "         [-0.0468,  0.0134, -0.0905,  0.1579,  0.0331],\n",
       "         [-0.2133,  0.1433, -0.1980,  0.2489,  0.0563],\n",
       "         [-0.1371,  0.1241,  0.0030, -0.0914, -0.0179],\n",
       "         [ 0.2758, -0.2010,  0.2189, -0.2239, -0.0558]])]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads = []\n",
    "for op in net.out_activations[::-1]:\n",
    "    grads.append(torch.autograd.grad(loss, op, retain_graph=True)[0])\n",
    "    print('------------')\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14128343, -2.91890857],\n",
       "       [ 2.57515734, -5.18890603],\n",
       "       [ 0.82365203, -0.85523361],\n",
       "       [-1.73909922,  2.8385638 ],\n",
       "       [ 0.47695332, -0.42796761],\n",
       "       [-2.07359372, -6.39049049],\n",
       "       [-2.46923772,  1.58436757],\n",
       "       [-3.14404445,  0.38541964],\n",
       "       [-1.38512863, -2.64496736],\n",
       "       [-1.07988552,  0.66171606],\n",
       "       [-0.72291186, -0.88400441],\n",
       "       [-3.08388612,  0.29422503],\n",
       "       [-1.28009607, -2.52365231],\n",
       "       [-0.16070638,  1.55309877],\n",
       "       [ 1.76819895,  0.30772287],\n",
       "       [-0.9863842 , -6.1461239 ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(_):\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "a(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model',\n",
       "  Net(\n",
       "    (l1): Linear(in_features=6, out_features=5, bias=True)\n",
       "    (l2): Linear(in_features=5, out_features=2, bias=True)\n",
       "  ))]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = list(net.model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
