{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 16, 6, 5, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = N//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = randn(N, D_in)\n",
    "np.random.seed(2)\n",
    "y = randn(N, D_out)\n",
    "\n",
    "x1, x2 = x[:mid], x[mid:]\n",
    "y1, y2 = y[:mid], y[mid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 5), (5,), (5, 2), (2,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "w1 = randn(D_in, H) \n",
    "np.random.seed(23)\n",
    "b1 = randn(H)\n",
    "np.random.seed(4)\n",
    "w2 = randn(H, D_out)\n",
    "np.random.seed(24)\n",
    "b2 = randn(D_out)\n",
    "w1.shape, b1.shape, w2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bias = True\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(6, 5, bias=use_bias)\n",
    "        self.l2 = nn.Linear(5, 2, bias=use_bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.l1(x))\n",
    "        x= self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAD(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(DAD, self).__init__()\n",
    "        self.grads = []\n",
    "        self.activations = []\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, *inputs, **kwargs):\n",
    "        childrens = dict(self.model.named_children())\n",
    "        for k, ch in childrens.items():\n",
    "            ch.register_forward_hook(self.hook_wrapper('forward', k))\n",
    "            ch.register_backward_hook(self.hook_wrapper('backward', k))\n",
    "        return self.model(*inputs, **kwargs)\n",
    "    \n",
    "    def hook_wrapper(self, hook_type, layer):\n",
    "        def hook_save(a, in_grad, out_grad):\n",
    "#             print(hook_type, layer, a, in_grad, out_grad)\n",
    "            if hook_type.lower() == 'forward':\n",
    "                for i, b in enumerate(in_grad):\n",
    "                    if b is not None:\n",
    "                        self.activations.append(b)\n",
    "                    break\n",
    "            if hook_type.lower()=='backward':\n",
    "                for i, c in enumerate(out_grad):\n",
    "                    if c is not None:\n",
    "                        self.grads.append(c)\n",
    "                    break\n",
    "        return hook_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = list(dict(net.named_parameters()).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1.weight', 'l2.weight']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l2.bias', 'l1.bias']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks[::-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1.weight', 'l1.bias', 'l2.weight', 'l2.bias']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(net.model.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (n, m), w in zip(net.named_parameters(), [w1, w2]):\n",
    "#     if 'bias' in n:\n",
    "#         m.data = torch.FloatTensor(w)\n",
    "#     elif 'weight' in n:\n",
    "#         m.data = torch.FloatTensor(w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "o = net(torch.FloatTensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.square(o-torch.Tensor(y)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6]) torch.Size([5, 6])\n",
      "torch.Size([5]) torch.Size([5])\n",
      "torch.Size([2, 5]) torch.Size([2, 5])\n",
      "torch.Size([2]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for p1, p2 in zip(net.parameters(), net.parameters()):\n",
    "    print(p1.grad.shape, p2.grad.shape)\n",
    "    p = torch.stack([p1, p2]).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4013, -0.6554], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4013, -0.6554], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1+p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [p.grad for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = grad_h * h * (1-h)\n",
    "# g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h: (16, 5)\n",
      "grad_y_pred: (16, 2)\n",
      "grad_w2:  (5, 2)\n",
      "grad_h:  (16, 5)\n",
      "grad_w1: (6, 5)\n"
     ]
    }
   ],
   "source": [
    "for t in range(10):\n",
    "    h = 1/(1+np.exp(-x.dot(w1)))\n",
    "    print('h:', h.shape)\n",
    "    \n",
    "    y_pred = h.dot(w2)\n",
    "    loss = np.square(y_pred-y).sum()\n",
    "#     print(t, loss)\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    print('grad_y_pred:', grad_y_pred.shape)\n",
    "    \n",
    "    grad_w2 = h.T.dot(grad_y_pred)\n",
    "    print('grad_w2: ', grad_w2.shape)\n",
    "    \n",
    "    \n",
    "    grad_h = grad_y_pred.dot(w2.T)\n",
    "    print('grad_h: ', grad_h.shape)\n",
    "    grad_w1 = x.T.dot(grad_h * h * (1-h))\n",
    "    print('grad_w1:', grad_w1.shape)\n",
    "    \n",
    "    w1 -= 1e-4 * grad_w1\n",
    "    w2 -= 1e-4 * grad_w2\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([5, 6]), torch.Size([2, 5])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.activations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.6243, -0.6118, -0.5282, -1.0730,  0.8654, -2.3015],\n",
       "         [ 1.7448, -0.7612,  0.3190, -0.2494,  1.4621, -2.0601],\n",
       "         [-0.3224, -0.3841,  1.1338, -1.0999, -0.1724, -0.8779],\n",
       "         [ 0.0422,  0.5828, -1.1006,  1.1447,  0.9016,  0.5025],\n",
       "         [ 0.9009, -0.6837, -0.1229, -0.9358, -0.2679,  0.5304],\n",
       "         [-0.6917, -0.3968, -0.6872, -0.8452, -0.6712, -0.0127],\n",
       "         [-1.1173,  0.2344,  1.6598,  0.7420, -0.1918, -0.8876],\n",
       "         [-0.7472,  1.6925,  0.0508, -0.6370,  0.1909,  2.1003],\n",
       "         [ 0.1202,  0.6172,  0.3002, -0.3522, -1.1425, -0.3493],\n",
       "         [-0.2089,  0.5866,  0.8390,  0.9311,  0.2856,  0.8851],\n",
       "         [-0.7544,  1.2529,  0.5129, -0.2981,  0.4885, -0.0756],\n",
       "         [ 1.1316,  1.5198,  2.1856, -1.3965, -1.4441, -0.5045],\n",
       "         [ 0.1600,  0.8762,  0.3156, -2.0222, -0.3062,  0.8280],\n",
       "         [ 0.2301,  0.7620, -0.2223, -0.2008,  0.1866,  0.4101],\n",
       "         [ 0.1983,  0.1190, -0.6707,  0.3776,  0.1218,  1.1295],\n",
       "         [ 1.1989,  0.1852, -0.3753, -0.6387,  0.4235,  0.0773]]),\n",
       " tensor([[0.9961, 0.3288, 0.9316, 0.1157, 0.7927],\n",
       "         [0.9700, 0.4206, 0.9543, 0.4903, 0.4622],\n",
       "         [0.5031, 0.7323, 0.8826, 0.9551, 0.9322],\n",
       "         [0.5229, 0.1865, 0.0679, 0.4786, 0.1254],\n",
       "         [0.9526, 0.7797, 0.6442, 0.0911, 0.8759],\n",
       "         [0.8348, 0.4353, 0.2912, 0.5252, 0.9352],\n",
       "         [0.0458, 0.5167, 0.2974, 0.9993, 0.6379],\n",
       "         [0.0572, 0.7731, 0.2820, 0.5395, 0.5316],\n",
       "         [0.8823, 0.6228, 0.1207, 0.7033, 0.8836],\n",
       "         [0.0860, 0.6491, 0.1703, 0.9547, 0.2690],\n",
       "         [0.0993, 0.5154, 0.5038, 0.9551, 0.5459],\n",
       "         [0.8717, 0.9557, 0.5985, 0.7656, 0.9480],\n",
       "         [0.6939, 0.8793, 0.8185, 0.1760, 0.9312],\n",
       "         [0.6611, 0.5484, 0.2876, 0.4105, 0.5495],\n",
       "         [0.6810, 0.4961, 0.1183, 0.2609, 0.4393],\n",
       "         [0.9498, 0.6251, 0.6215, 0.0743, 0.6257]], grad_fn=<SigmoidBackward>)]"
      ]
     },
     "execution_count": 935,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00639449000000003"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.32010551 - 0.3265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208.33333333333218"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.0048000000000000265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['l1.weight', 'l1.bias', 'l2.weight', 'l2.bias'])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parm = dict(net.model.named_parameters())\n",
    "parm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1', 'l2']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child = list(dict(net.model.named_children()).keys())\n",
    "child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.0944, 0.2803], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1736,  0.0088, -0.3068,  0.2007, -0.0979], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for c in child[::-1]:\n",
    "    print(parm.get(f\"{c}.bias\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randn(16, 784)\n",
    "t2 = torch.randn(16, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
