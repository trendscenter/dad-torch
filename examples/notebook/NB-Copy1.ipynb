{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 16, 6, 5, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = N//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = randn(N, D_in)\n",
    "np.random.seed(2)\n",
    "y = randn(N, D_out)\n",
    "\n",
    "x1, x2 = x[:mid], x[mid:]\n",
    "y1, y2 = y[:mid], y[mid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 5), (5, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "w1 = randn(D_in, H) \n",
    "np.random.seed(4)\n",
    "w2 = randn(H, D_out)\n",
    "w1.shape, w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(6, 5, bias=False)\n",
    "        self.l2 = nn.Linear(5, 2, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.l1(x))\n",
    "        x= self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net1 = Net()\n",
    "net2 = Net()\n",
    "for p, p1, p2, a in zip(net.parameters(), net1.parameters(), net2.parameters(), [w1, w2]):\n",
    "    p.data *= 0\n",
    "    p.data += torch.FloatTensor(a.T)\n",
    "    \n",
    "    p1.data *= 0\n",
    "    p1.data += torch.FloatTensor(a.T)\n",
    "    \n",
    "    p2.data *= 0\n",
    "    p2.data += torch.FloatTensor(a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_wrapper(site, hook_type, layer):\n",
    "    print(f\"**** {site}, {hook_type}, {layer}  ****\")\n",
    "    \n",
    "    name = f\"Site:{site}-Type:{hook_type}-Layer:{layer}\"\n",
    "    def hook_save(a, in_grad, out_grad):\n",
    "        print('------IN---------')\n",
    "        if hook_type.lower() == 'forward':\n",
    "            for i, b in enumerate(in_grad):\n",
    "                if b is not None:\n",
    "                    print(name)\n",
    "                    print(b)\n",
    "                break\n",
    "        print('\\n------------OUT-----------')\n",
    "        if hook_type.lower()=='backward':\n",
    "            for i, c in enumerate(out_grad):\n",
    "                if c is not None:\n",
    "                    print(name)\n",
    "                    print(c)\n",
    "                break\n",
    "        print('****************************')\n",
    "    return hook_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hook_wrapper(site, hook_type, layer, save_to='', debug=False):\n",
    "#     if debug:\n",
    "#         print(f\"**** {site}, {hook_type}, {layer} ****\")\n",
    "\n",
    "#     name = os.path.join(save_to, f\"Site:{site}-Type:{hook_type}-Layer:{layer}\")\n",
    "\n",
    "#     def hook_save(a, in_grad, out_grad):\n",
    "#         if hook_type.lower() == 'forward':\n",
    "#             for i, b in enumerate(in_grad):\n",
    "#                 if b is not None:\n",
    "#                     np.save(name + f\"-IO:in-Index:{i}.npy\", b.clone().detach().numpy())\n",
    "#                 break\n",
    "#         if hook_type.lower() == 'backward':\n",
    "#             for i, c in enumerate(out_grad):\n",
    "#                 if c is not None:\n",
    "#                     np.save(name + f\"-IO:out-index:{i}.npy\", c.clone().detach().numpy())\n",
    "#                 break\n",
    "\n",
    "#     return hook_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** 0, forward, l1  ****\n",
      "**** 0, backward, l1  ****\n",
      "**** 0, forward, l2  ****\n",
      "**** 0, backward, l2  ****\n"
     ]
    }
   ],
   "source": [
    "childrens = dict(net.named_children())\n",
    "for k, ch in childrens.items():\n",
    "    ch.register_forward_hook(hook_wrapper(0, 'forward', k))\n",
    "    ch.register_backward_hook(hook_wrapper(0, 'backward', k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1', 'l2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k, V in net.named_children()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h: (16, 5)\n",
      "grad_y_pred: (16, 2)\n",
      "grad_w2:  (5, 2)\n",
      "grad_h:  (16, 5)\n",
      "grad_w1: (6, 5)\n"
     ]
    }
   ],
   "source": [
    "for t in range(10):\n",
    "    h = 1/(1+np.exp(-x.dot(w1)))\n",
    "    print('h:', h.shape)\n",
    "    y_pred = h.dot(w2)\n",
    "    loss = np.square(y_pred-y).sum()\n",
    "#     print(t, loss)\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    print('grad_y_pred:', grad_y_pred.shape)\n",
    "    \n",
    "    grad_w2 = h.T.dot(grad_y_pred)\n",
    "    print('grad_w2: ', grad_w2.shape)\n",
    "    \n",
    "    \n",
    "    grad_h = grad_y_pred.dot(w2.T)\n",
    "    print('grad_h: ', grad_h.shape)\n",
    "    grad_w1 = x.T.dot(grad_h * h * (1-h))\n",
    "    print('grad_w1:', grad_w1.shape)\n",
    "    \n",
    "    w1 -= 1e-4 * grad_w1\n",
    "    w2 -= 1e-4 * grad_w2\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------IN---------\n",
      "Site:0-Type:forward-Layer:l1\n",
      "tensor([[ 1.6243, -0.6118, -0.5282, -1.0730,  0.8654, -2.3015],\n",
      "        [ 1.7448, -0.7612,  0.3190, -0.2494,  1.4621, -2.0601],\n",
      "        [-0.3224, -0.3841,  1.1338, -1.0999, -0.1724, -0.8779],\n",
      "        [ 0.0422,  0.5828, -1.1006,  1.1447,  0.9016,  0.5025],\n",
      "        [ 0.9009, -0.6837, -0.1229, -0.9358, -0.2679,  0.5304],\n",
      "        [-0.6917, -0.3968, -0.6872, -0.8452, -0.6712, -0.0127],\n",
      "        [-1.1173,  0.2344,  1.6598,  0.7420, -0.1918, -0.8876],\n",
      "        [-0.7472,  1.6925,  0.0508, -0.6370,  0.1909,  2.1003],\n",
      "        [ 0.1202,  0.6172,  0.3002, -0.3522, -1.1425, -0.3493],\n",
      "        [-0.2089,  0.5866,  0.8390,  0.9311,  0.2856,  0.8851],\n",
      "        [-0.7544,  1.2529,  0.5129, -0.2981,  0.4885, -0.0756],\n",
      "        [ 1.1316,  1.5198,  2.1856, -1.3965, -1.4441, -0.5045],\n",
      "        [ 0.1600,  0.8762,  0.3156, -2.0222, -0.3062,  0.8280],\n",
      "        [ 0.2301,  0.7620, -0.2223, -0.2008,  0.1866,  0.4101],\n",
      "        [ 0.1983,  0.1190, -0.6707,  0.3776,  0.1218,  1.1295],\n",
      "        [ 1.1989,  0.1852, -0.3753, -0.6387,  0.4235,  0.0773]])\n",
      "\n",
      "------------OUT-----------\n",
      "****************************\n",
      "------IN---------\n",
      "Site:0-Type:forward-Layer:l2\n",
      "tensor([[0.9924, 0.3231, 0.9674, 0.0482, 0.6547],\n",
      "        [0.9431, 0.4144, 0.9785, 0.2714, 0.2988],\n",
      "        [0.3419, 0.7272, 0.9424, 0.8918, 0.8720],\n",
      "        [0.3601, 0.1826, 0.1368, 0.2623, 0.0664],\n",
      "        [0.9116, 0.7752, 0.7976, 0.0374, 0.7778],\n",
      "        [0.7217, 0.4290, 0.4720, 0.2999, 0.8773],\n",
      "        [0.0241, 0.5102, 0.4795, 0.9981, 0.4662],\n",
      "        [0.0302, 0.7685, 0.4609, 0.3121, 0.3601],\n",
      "        [0.7937, 0.6167, 0.2301, 0.4786, 0.7900],\n",
      "        [0.0461, 0.6432, 0.3087, 0.8909, 0.1543],\n",
      "        [0.0535, 0.5089, 0.6884, 0.8917, 0.3734],\n",
      "        [0.7772, 0.9546, 0.7644, 0.5585, 0.9005],\n",
      "        [0.5378, 0.8765, 0.9075, 0.0764, 0.8702],\n",
      "        [0.5003, 0.5420, 0.4676, 0.2124, 0.3769],\n",
      "        [0.5228, 0.4897, 0.2261, 0.1203, 0.2798],\n",
      "        [0.9066, 0.6191, 0.7814, 0.0302, 0.4532]], grad_fn=<SigmoidBackward>)\n",
      "\n",
      "------------OUT-----------\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "p1 = net(torch.Tensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.square(p1-torch.Tensor(y)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------IN---------\n",
      "\n",
      "------------OUT-----------\n",
      "Site:0-Type:backward-Layer:l2\n",
      "tensor([[-0.1465, -2.9575],\n",
      "        [ 2.5708, -5.2243],\n",
      "        [ 0.8088, -0.8860],\n",
      "        [-1.7431,  2.8321],\n",
      "        [ 0.4652, -0.4630],\n",
      "        [-2.0848, -6.4180],\n",
      "        [-2.4813,  1.5732],\n",
      "        [-3.1565,  0.3753],\n",
      "        [-1.3973, -2.6701],\n",
      "        [-1.0906,  0.6543],\n",
      "        [-0.7350, -0.8989],\n",
      "        [-3.1005,  0.2585],\n",
      "        [-1.2938, -2.5556],\n",
      "        [-0.1695,  1.5346],\n",
      "        [ 1.7610,  0.2945],\n",
      "        [-0.9949, -6.1776]])\n",
      "****************************\n",
      "------IN---------\n",
      "\n",
      "------------OUT-----------\n",
      "Site:0-Type:backward-Layer:l1\n",
      "tensor([[-1.1275e-02, -4.1676e-01,  1.4981e-01, -7.6879e-02,  7.5620e-01],\n",
      "        [-1.3308e-01, -1.5006e+00,  1.5181e-01, -9.4760e-01,  1.4349e+00],\n",
      "        [-9.0469e-02, -2.8171e-01,  5.7864e-02, -1.0170e-01,  1.4345e-01],\n",
      "        [ 3.0594e-01,  5.5226e-01, -4.4375e-01,  5.4646e-01, -2.3724e-01],\n",
      "        [-1.6758e-02, -1.3668e-01,  8.7033e-02, -2.0798e-02,  1.1853e-01],\n",
      "        [-6.6561e-01, -5.8186e-01,  2.7518e+00, -5.2305e-01,  7.1794e-01],\n",
      "        [ 1.5528e-02,  8.9019e-01, -3.6311e-01,  4.7791e-03, -6.5439e-01],\n",
      "        [ 8.2106e-04,  6.0551e-01,  1.8030e-01,  4.8717e-01, -3.4088e-01],\n",
      "        [-2.3018e-01, -1.0884e-01,  8.5299e-01, -1.7299e-01,  4.3126e-01],\n",
      "        [ 1.1953e-02,  3.5339e-01, -1.2391e-01,  1.0675e-01, -1.4526e-01],\n",
      "        [-2.4659e-02,  2.7127e-02,  3.7145e-01, -5.9828e-03,  1.8420e-01],\n",
      "        [-4.7667e-03,  1.4172e-01,  1.5981e-01,  5.3333e-01, -1.1892e-01],\n",
      "        [-3.3386e-01, -5.2388e-02,  3.8534e-01, -4.8798e-02,  2.8265e-01],\n",
      "        [ 1.8966e-01,  3.0613e-01, -5.8772e-01,  1.7203e-01, -4.2676e-01],\n",
      "        [ 5.8943e-02, -3.8721e-01, -2.1052e-01, -1.0202e-01,  4.9804e-02],\n",
      "        [-2.6568e-01, -7.7678e-01,  1.7434e+00, -8.9317e-02,  1.6747e+00]])\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1.weight Parameter containing:\n",
      "tensor([[ 1.7886, -0.3548, -1.3139, -0.4047, -1.1850, -0.7130],\n",
      "        [ 0.4365, -0.0827,  0.8846, -0.5454, -0.2056,  0.6252],\n",
      "        [ 0.0965, -0.6270,  0.8813, -1.5465,  1.4861, -0.1605],\n",
      "        [-1.8635, -0.0438,  1.7096,  0.9824,  0.2367, -0.7688],\n",
      "        [-0.2774, -0.4772,  0.0500, -1.1011, -1.0238, -0.2300]],\n",
      "       requires_grad=True)\n",
      "l2.weight Parameter containing:\n",
      "tensor([[ 0.0506, -0.9959, -0.4183, -0.6477,  0.3323],\n",
      "        [ 0.5000,  0.6936, -1.5846,  0.5986, -1.1475]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for k, p in net.named_parameters():\n",
    "    print(k,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in net.parameters():\n",
    "    p.grad.detach_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.load_state_dict(torch.load('chk.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: AK'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Name: {}\".format('AK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 4.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.T.mm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.65050639, -20.05829342],\n",
       "       [ -8.77522329, -11.72429864],\n",
       "       [ -5.49211195, -17.99616749],\n",
       "       [ -7.0682281 ,  -3.19438619],\n",
       "       [ -7.95513326, -15.59246294]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.T.dot(grad_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.6505, -20.0583],\n",
       "        [ -8.7752, -11.7243],\n",
       "        [ -5.4921, -17.9962],\n",
       "        [ -7.0682,  -3.1944],\n",
       "        [ -7.9551, -15.5925]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(h).T.mm(torch.Tensor(grad_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([5, 6]), torch.Size([2, 5])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.grad.shape for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1.weight tensor([[-0.1147,  0.2385, -0.1600,  2.0195,  0.8291,  0.4634],\n",
      "        [-5.2419,  3.7720,  1.7932,  3.2138, -1.9054,  4.8540],\n",
      "        [ 0.9208, -0.0698, -1.5408, -6.1658, -2.3991, -0.7603],\n",
      "        [-1.2793,  2.9918,  0.6647,  0.7110, -1.0412,  3.3018],\n",
      "        [ 6.0451, -2.3750, -1.7649, -4.2975,  2.3372, -5.0113]])\n",
      "l2.weight tensor([[ -3.6777,  -8.8142,  -5.5268,  -7.0952,  -7.9853],\n",
      "        [-20.1403, -11.7940, -18.0874,  -3.2346, -15.6785]])\n"
     ]
    }
   ],
   "source": [
    "for l, ch in net.named_parameters():\n",
    "    print(l, ch.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
